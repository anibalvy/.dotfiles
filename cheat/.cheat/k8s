# Control Plane Components

Control Plane Components:

    kube-apiserver
    etcd
    kube-scheduler
    kube-controller-manager
    cloud-controller-manager

Node Components:

   - kubelet 
    	is the primary “node agent” that runs on each node. 
	  It has the following missions:
	    - Monitor the Pods assigned to the Node
	    - Mount volumes that needed to mount the Pod
	    - Download the secret of the Pod
	    - Run the container in the pod through docker/rkt
	    - Periodically execute the liveness probe
	    - Report the status of the Pod
	    - Report the status of Node
   - kube-proxy
   - Container runtime

The k8s cluster has three types of IP addresses, which are as follows:

    - Node IP , the IP address of the Node node, that is, the network card address of the server
    - Pod IP , the IP address of the Pod
    - Cluster IP , also called Service IP , IP address of Service

Services: Kube-proxy
  - Cluster IP: will create an IP that will loadBalance all container by spec.selectors.role
  - Node Port: 
   		will create a port in every node, even if pod is not running inside; and will route traffic to that node
		after creation you can get the 'EXTERNAL-IP' from "from kubectl get nodes -o wide", and use that ip with the port configured.
               
  - Load Balancer: will use cloud loadbalancer

Volumenes:
	- Host path: mount path from node to pod
	- downward API: gives k8s info to pods
	- configmap: a config values that resides in k8s

RABC:
        - Roles: declare permissions that affect namespaces
		- Resource
		- Verbs: actions like get, list, delete, create
	- RoleBinding: assing user to roles
		- Role
		- Subject
		- ServiceAccount
	- ClusterRole: declare permissions that affect all Cluster
	- CluserRoleBinding: assing user to Cluster roles
	- ServiceAccount: assing permissions to Pod (like a user to pod)

     Create user:
       - Create key:
       		openssl genrsa -out <user>.key 2048
       - Create certificate service request  CSR:
                openssl req -new -key <user>.key -out <user>.csr -subj "/CN=<user>/O=<org>"
       - Sign it:
                openssl x509 -req -in <user>.csr -CA <path>/ca.crt -CAkey <path>/ca.key -CAcreateserial -out <user>.crt
       - Create user:
                kubectl config set-credentials <user> --client-certificate=<user>.crt --client-key=<user>.key
       - Create context for user:
                kubectl config set-context <user>-context --cluster=<clustername> 

Addons: 

    DNS
    Web UI (Dashboard)
    Container Resource Monitoring
    Cluster-level Logging

Cluster Architecture:
	- Nodes
	  	they are "Master nodes" and "Worker nodes"
	  	The components on a node include the kubelet, a container runtime, and the kube-proxy.
	- 
	- Communication between Nodes and the Control Plane
	- Controllers
	- Cloud Controller Manager
	- About cgroup v2
	- Container Runtime Interface (CRI)
	- Garbage Collection

CNI (Container Network Interface) API:
        - kubenet
	- calico
	- cillium

pods:    deployments
demoset: pods that are deployed to all nodes 

labels and annotations:
The biggest difference between annotations and labels in Kubernetes is this: while labels attach identifying metadata to a K8s object, annotations attach additional information that is not identifying.

# installing metrics server
kubectl top nodes
kubectl top pods

# MANIFESTs

## 35 02-pod.yml
### if it is killed, it will NOT auto deploy again
apiVersion: v1
kind: Pod
metadata:
  name: nginx
spec:
  containers:
  - name: nginx
    image: nginx:alpine
    env:
    - name: MI_VARIABLE
      value: "pelado"
    - name: MI_OTRA_VARIABLE
      value: "pelade"
    - name: DD_AGENT_HOST
      valueFrom:
        fieldRef: # downward API, values given by K8s
          fieldPath: status.hostIP
    resources:
      requests: # minimum 
        memory: "64Mi"
        cpu: "200m" # a core is 1000m (milicore)  
      limits: # max
        memory: "128Mi"
        cpu: "500m"
    readinessProbe:
      httpGet:
        path: /
        port: 80
      initialDelaySeconds: 5
      periodSeconds: 10
    livenessProbe:
      tcpSocket:
        port: 80
      initialDelaySeconds: 15
      periodSeconds: 20
    ports:
    - containerPort: 80

## 35 03-daemoset.yml
### it will deployed 1 pod in all nodes
### usefull for monitoring
apiVersion: apps/v1
kind: DaemonSet
metadata:
  name: nginx-deployment
spec:
  selector:
    matchLabels:
      app: nginx
  template:
    metadata:
      labels:
        app: nginx
    spec:
      containers:
      - name: nginx
        image: nginx:alpine
        env:
        - name: MI_VARIABLE
          value: "pelado"
        - name: MI_OTRA_VARIABLE
          value: "pelade"
        - name: DD_AGENT_HOST
          valueFrom:
            fieldRef:
              fieldPath: status.hostIP
        resources:
          requests:
            memory: "64Mi"
            cpu: "200m"
          limits:
            memory: "128Mi"
            cpu: "500m"
        readinessProbe:
          httpGet:
            path: /
            port: 80
          initialDelaySeconds: 5
          periodSeconds: 10
        livenessProbe:
          tcpSocket:
            port: 80
          initialDelaySeconds: 15
          periodSeconds: 20
        ports:
        - containerPort: 80


## 35 04-deployment.yml
### allow that the pod get automatically running
### if it is killed, it will auto deploy again
apiVersion: apps/v1
kind: Deployment
metadata:
  name: nginx-deployment
spec:
  selector:
    matchLabels:
      app: nginx
  replicas: 2
  template:
    metadata:
      labels:
        app: nginx
    spec:
      containers:
      - name: nginx
        image: nginx:alpine
        env:
        - name: MI_VARIABLE
          value: "pelado"
        - name: MI_OTRA_VARIABLE
          value: "pelade"
        - name: DD_AGENT_HOST
          valueFrom:
            fieldRef:
              fieldPath: status.hostIP
        resources:
          requests:
            memory: "64Mi"
            cpu: "200m"
          limits:
            memory: "128Mi"
            cpu: "500m"
        readinessProbe:
          httpGet:
            path: /
            port: 80
          initialDelaySeconds: 5
          periodSeconds: 10
        livenessProbe:
          tcpSocket:
            port: 80
          initialDelaySeconds: 15
          periodSeconds: 20
        ports:
        - containerPort: 80


## 35 - 07-ClusterIP.yml
apiVersion: apps/v1
kind: Deployment
metadata:
  name: hello
spec:
  replicas: 3
  selector:
    matchLabels:
      role: hello
  template:
    metadata:
      labels:
        role: hello
    spec:
      containers:
      - name: hello
        image: gcr.io/google-samples/hello-app:1.0
        ports:
        - containerPort: 8080

---
apiVersion: v1
kind: Service
metadata:
  name: hello
spec:
  ports:
  - port: 8080
    targetPort: 8080
  selector:
    role: hello # here it is said which pods to take.



# 35 - 12-configmamp.yaml
# files with config hosted on K8s
apiVersion: v1
kind: ConfigMap
metadata:
  name: game-demo
data:
  # property-like keys; each key maps to a simple value
  player_initial_lives: "3"
  ui_properties_file_name: "user-interface.properties"
  #
  # file-like keys
  game.properties: |
    enemy.types=aliens,monsters
    player.maximum-lives=5
  user-interface.properties: |
    color.good=purple
    color.bad=yellow
    allow.textmode=true

## cost calculator - https://learnk8s.io/kubernetes-instance-calculator
