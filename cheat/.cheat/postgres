# Fillfactor - [https://www.cybertec-postgresql.com/en/what-is-fillfactor-and-how-does-it-affect-postgresql-performance/]
The fillfactor for a table is a percentage between 10 and 100. 100 (complete packing) is the default. 
When a smaller fillfactor is specified, INSERT operations pack table pages only to the indicated percentage; 
the remaining space on each page is reserved for updating rows on that page. This gives UPDATE a chance 
to place the updated copy of a row on the same page as the original, which is more efficient than placing it on a different page. 
For a table, whose entries are never updated, complete packing is the best choice, but in heavily updated tables smaller fillfactors are appropriate. 
This parameter cannot be set for TOAST tables.

-- leave 10% of block space unused when inserting data
ALTER TABLE pgbench_accounts SET (fillfactor = 90);

# JSON [https://dzone.com/articles/using-jsonb-in-postgresql-how-to-effectively-store]
# TIMESTAMP [https://www.cybertec-postgresql.com/en/time-zone-management-in-postgresql/]

# size of DB
SELECT pg_size_pretty( pg_database_size('databname'));
# size of table 
SELECT pg_size_pretty( pg_total_relation_size('tablename'));

# pg dump
pg_dump --file "~/Backups/DB_-202208051053.sql" --host "<url>" --port "5432" --username "master" --no-password --verbose --role "master" --format=p --create --section=pre-data --section=data --section=post-data --inserts --encoding "UTF8" "vote"

# see tuples
select ctid from <table>;

  # see dead tuples
  select n_live_tup, n_dead_tup, relname
    from pg_stat_all_tables
   where relname = '<table_name>';

# see transactions number 
select xmin, xmax from <table>;
# xmin: transaction that create that row 
# xmax: transaction that kill that row


# -- check which sessions are encrypted
SELECT datname,usename, ssl, client_addr 
  FROM pg_stat_ssl
  JOIN pg_stat_activity
    ON pg_stat_ssl.pid = pg_stat_activity.pid;

SELECT * FROM pg_stat_activity JOIN pg_stat_ssl USING(pid);

##
# find tables and make delete statement
SELECT -- * --table_schema || '.' || table_name
       'drop table '|| table_name ||'; '
  FROM information_schema.tables
 WHERE table_type = 'BASE TABLE'
   AND table_schema NOT IN ('pg_catalog', 'information_schema')
   and table_name like 'my_table%';
   
   

SELECT  * --table_schema || '.' || table_name
       --'drop table '|| table_name ||'; '
  FROM information_schema.sequences;
  
  
SELECT  * 
  FROM information_schema.schemata;

# -- check roles
SELECT r.rolname as username,r1.rolname as "role"
FROM pg_catalog.pg_roles r
    JOIN pg_catalog.pg_auth_members m
        ON (m.member = r.oid)
    JOIN pg_roles r1 ON (m.roleid=r1.oid)
WHERE r.rolcanlogin
ORDER BY 1;

show max_worker_processes;            -- quantity of parallel workers (max_parallel_workers + max_parallel_maintenance_workers)
show max_parallel_workers;            -- quantity of parallel workers
show max_parallel_workers_per_gather; -- quantity of parallel workers using in a table that gt min_parallel_table_scan_size
show min_parallel_table_scan_size;    -- min size that parallel workers will run
set max_parallel_workers_per_gather to 10; -- global
alter table <table> set (parallel_workers = 10); -- table level


show autovacuum_freeze_max_age;       -- Check the autovacuum frequency in (transaction freeze limits)
show hba_file;                        -- location of identity file
:version                              -- show pg version in psql (>15)
select version();                     -- show pg version

# estimate of wasted space before vacuum:
SELECT 
        schemaname , relname , 
        pg_total_relation_size(relid) AS total_size,
        n_live_tup , n_dead_tup , 
        n_dead_tup * 100.0 / 
        CASE n_live_tup WHEN 0 THEN 1 ELSE n_live_tup END  AS dead_ratio,
        pg_total_relation_size(relid) * n_dead_tup  / CASE n_live_tup WHEN 0 THEN 1 ELSE n_live_tup END AS wasted_space
    FROM 
        pg_catalog.pg_stat_all_tables 
    WHERE
        schemaname = 'public'
    ORDER BY 
        wasted_space DESC;

#  Get expensive querys 
CREATE EXTENSION pg_stat_statements;
SELECT query,
       round(total_exec_time::numeric, 2) as total_exec_time_in_ms,
       calls,
       round(mean_exec_time::numeric, 2) as mean_in_ms,
       round((100 * total_exec_time / sum(total_exec_time::numeric)
             OVER ())::numeric, 2) AS percentage_overall
  FROM pg_stat_statements
 -- WHERE 
 ORDER BY total_exec_time DESC
 LIMIT 20;

# table reads
SELECT schemaname, relname, 
       seq_scan,        -- how often the table is read sequentialy
       seq_tup_read,    -- how many row are found on read sequentialy      
       idx_scan,        -- how many found by the index
       seq_tup_read / seq_scan as avg_size_of_seq_scan -- 
  FROM pg_stat_user_tables
 WHERE seq_scan > 0
 ORDER BY seq_tup_read DESC;


# Time zone
show timezone;
SELECT * FROM pg_timezone_names;
ALTER DATABASE vote SET TIMEZONE TO 'America/Santiago';
SET TIMEZONE TO 'America/Santiago';
SET TIMEZONE TO 'UTC';
select now() at time zone 'America/Santiago' from table;

# pgtune https://pgtune.leopard.in.ua/
# DB Version: 15
# OS Type: linux
# DB Type: oltp
# Total Memory (RAM): 4 GB
# CPUs num: 2
# Connections num: 100
# Data Storage: hdd

max_connections = 100
shared_buffers = 1GB
effective_cache_size = 3GB
maintenance_work_mem = 256MB
checkpoint_completion_target = 0.9
wal_buffers = 16MB
default_statistics_target = 100
random_page_cost = 4
effective_io_concurrency = 2
work_mem = 5242kB
min_wal_size = 2GB
max_wal_size = 8GB

# check parameters
show max_connections;

# patitioning types
#   Declarative partitioning
#    - since 10
#    - minimal maintenance
#    - best for most usercases
#   Ihnerited partitioning (old method)
#    - difficult to setup
#    - more flexible

# Partitioning by methods
# - Range:     usually by date
# - List:      categories
# - Hash:      taking a col like product using a modulus to determine the partition: n % 3 = 0, 1, 2
# - Composite: 

# Partitioning by range
# - create table
# create table customer ( id integer, name text, age numeric) partition by range (age);
# - create partitions
# create table customers_young  partition of customer for values from (MINVALUE) to (25);
# create table customers_medium partition of customer for values from (25) to (75);
# create table customers_old    partition of customer for values from (75) to (MAXVALUE);
#
# - check partitions
#  # \d+ customers
#  # select tableoid::regclass, * from customers;
#

# text search
select * from <table> where field like '%<my_search>%'
select * from <table> where field ilike '%<my_search>%'
select * from <table> where field ~ '<my_search>'
select * from <table> where field &@~ '<my_search>'   # Full-text search, try use special index like PGroonga for column 'field'

